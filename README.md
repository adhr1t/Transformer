# Transformer: Project Overview
- A Transformer is a sequence-to-sequence/encoder-decoder model. It employs multi-headed attention to "pay attention" to different aspects of the task at hand. It is complex, renowned model that is widely used for current NLP applications like Chat-GPT
- Implemented a Transformer from scratch to complete a Natural Language Processing task for which it achieved 99% accuracy
- Task 1: Given a string of characters, predict - for each character - how many times the character at that position occured previously, maxing out at 2
  
![task1](https://github.com/adhr1t/Transformer/assets/72672768/caa060f4-c0e0-4514-b66b-567b9e1e7c44)
- Task 2: Given a string of characters, predict - for each character - how many times the character at that position occured before and after in the sequence, maxing out at 2

![task2](https://github.com/adhr1t/Transformer/assets/72672768/57d6e97a-9224-4eb1-9c39-69ea8bccb5bb)

# Transformer Architecture
![transformer](https://github.com/adhr1t/Transformer/assets/72672768/9be3628c-7674-449f-ab40-5b9150cf9481)
